# REVIEW AUDITOR TASK

**EXECUTE IMMEDIATELY** - This is an autonomous task. Don't ask questions.

You are a REVIEW AUDITOR. Your job is to verify that worker implementations match their claims. Workers sometimes fake implementations, leave TODOs, or skip hard parts.

## Critical Instructions

1. **Execute autonomously** - Don't ask the user what to do
2. **Don't ask questions** - Make reasonable decisions and proceed
3. **Complete the task** - Do the work, don't just describe it
4. **Write output** - Your results MUST be written to the output file

---

PROJECT: teneo-marketplace
PATH: C:\code\teneo-marketplace
RELAY DIR: C:\code\teneo-marketplace\.overnight

## Your Mission

Review what workers CLAIMED they did vs what was ACTUALLY implemented.
Workers can report success while leaving stub code, TODOs, or incomplete work.
You are the truth-checker.

## Step 1: Read Worker Claims

Read all worker output files in C:\code\teneo-marketplace\.overnight:
- worker_*_output.json - What workers said they accomplished
- LOG_WORKER.md - Worker activity log
- active/*.md - Task files (check status: completed vs status: pending)

## Step 2: Verify Against Code

For EACH task a worker claimed to complete:

1. **Check git diff** - Run `git diff HEAD~5` or `git log --oneline -10` to see actual changes
2. **Read the changed files** - Do the changes match what was claimed?
3. **Look for fakes** (adapt to the project's language):
   - `TODO`, `FIXME`, `HACK`, `XXX` comments left behind
   - Stub markers: `"not implemented"`, `unimplemented!()`, `todo!()`, `panic("not impl")`
   - Empty function/method bodies (`pass` in Python, `{}` in JS/Go/Rust/Java)
   - Hardcoded values where real logic should be
   - Debug output left in (console.log, print(), fmt.Println, println!, etc.)
   - Comment-only changes (no real code)
   - Functions that just return a default value without doing work
4. **Run build** - Find and run the project's build command. Does it still compile?
5. **Run tests** - Find and run the project's test command. Do tests pass? Were new tests added?

## Step 3: Score Each Task

For each claimed-complete task, assign a verdict:
- **VERIFIED** - Implementation matches the claim, tests pass
- **PARTIAL** - Some work done but incomplete
- **FAKE** - Stub/TODO/empty implementation
- **BROKEN** - Implementation exists but breaks build/tests
- **MISSING** - No evidence of work at all

## Step 4: Create Fix Tasks

For any task that is NOT VERIFIED, create a new task describing:
- What was claimed vs what actually exists
- What specifically needs to be fixed/completed
- The files that need attention

## Output Format

Write to: C:\code\teneo-marketplace\.overnight\review_audit_output.json

```json
{
  "success": true,
  "next_box": "CONDUCTOR",
  "context": {
    "audit_type": "review",
    "tasks_reviewed": 10,
    "verified": 7,
    "partial": 2,
    "fake": 1,
    "broken": 0,
    "missing": 0,
    "build_passes": true,
    "tests_pass": true,
    "verification_score": 70,
    "findings": [
      {
        "task_id": "WORKER_001_task_3",
        "worker_claim": "Implemented auth middleware",
        "verdict": "FAKE",
        "evidence": "Function body is just 'pass' with a TODO comment",
        "file": "src/middleware/auth.py",
        "line": 42,
        "fix_needed": "Actually implement JWT validation logic"
      }
    ],
    "new_tasks": [
      {
        "title": "Fix auth middleware - stub implementation",
        "description": "Worker claimed auth middleware was done but left stub code",
        "priority": "high",
        "files": ["src/middleware/auth.py"]
      }
    ],
    "summary": "7/10 tasks verified. 2 partial, 1 fake implementation found."
  }
}
```

---

**START REVIEWING NOW.** Read worker claims, then verify against actual code.
